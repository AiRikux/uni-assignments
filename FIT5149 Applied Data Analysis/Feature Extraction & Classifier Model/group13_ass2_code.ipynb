{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d530f21f",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7c39a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20cffd7",
   "metadata": {},
   "source": [
    "# Training Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2f455bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./train_data_withlabels.csv\")\n",
    "train = train.iloc[:, 1:]\n",
    "\n",
    "# change type from string to datetime object\n",
    "train.localminute = pd.to_datetime(train.localminute)\n",
    "\n",
    "# create new columns\n",
    "train['month'] = train.localminute.dt.month\n",
    "train['date'] = train.localminute.dt.day\n",
    "train['weekday'] = train.localminute.dt.weekday\n",
    "train['hour'] = train.localminute.dt.hour\n",
    "train['minute'] = train.localminute.dt.minute\n",
    "\n",
    "# remove localminute column\n",
    "train = train.iloc[:, 1:]\n",
    "\n",
    "# move target column just for ease\n",
    "target = train.pop('target')\n",
    "train['target'] = target\n",
    "\n",
    "# get column names\n",
    "col_names = train.columns.to_list()\n",
    "\n",
    "# normalise the data\n",
    "target = train.target\n",
    "feature_a = train.iloc[:,0:7].columns.to_list()\n",
    "feature_b = train.iloc[:,7:-1].columns.to_list()\n",
    "normal_standard = ColumnTransformer([('standardscaler', StandardScaler(), feature_a)], \n",
    "                                    remainder='passthrough')\n",
    "normal_minmax = ColumnTransformer([('minmaxscaler', MinMaxScaler(), feature_b)], \n",
    "                                  remainder='passthrough')\n",
    "\n",
    "# use sklearn to normalize data\n",
    "train_normal = pd.DataFrame(normal_standard.fit_transform(train))\n",
    "# rename columns\n",
    "train_normal.columns = col_names\n",
    "# do the rest\n",
    "train_normal = pd.DataFrame(normal_minmax.fit_transform(train_normal))\n",
    "\n",
    "# rename columns\n",
    "train_normal.columns = feature_b + feature_a + [\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3862f892",
   "metadata": {},
   "source": [
    "## Training and Validation Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e09b2ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                 target   R-squared (uncentered):                   0.421\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.421\n",
      "Method:                 Least Squares   F-statistic:                          2.495e+04\n",
      "Date:                Tue, 07 Jun 2022   Prob (F-statistic):                        0.00\n",
      "Time:                        20:44:51   Log-Likelihood:                      1.1714e+05\n",
      "No. Observations:              377828   AIC:                                 -2.343e+05\n",
      "Df Residuals:                  377817   BIC:                                 -2.341e+05\n",
      "Df Model:                          11                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "date                      0.0402      0.001     45.800      0.000       0.038       0.042\n",
      "weekday                   0.0326      0.001     41.541      0.000       0.031       0.034\n",
      "hour                     -0.0164      0.001    -18.697      0.000      -0.018      -0.015\n",
      "minute                    0.0398      0.001     46.514      0.000       0.038       0.042\n",
      "total_load                0.0899      0.000    214.680      0.000       0.089       0.091\n",
      "ab_diff                  -0.0047      0.000    -12.563      0.000      -0.005      -0.004\n",
      "re_diff                   0.0078      0.000     26.876      0.000       0.007       0.008\n",
      "window_mean               0.0824      0.001    141.424      0.000       0.081       0.084\n",
      "window_dev               -0.0010      0.001     -1.517      0.129      -0.002       0.000\n",
      "window_crossing_point    -0.0364      0.000   -123.303      0.000      -0.037      -0.036\n",
      "window_peak              -0.0231      0.001    -31.012      0.000      -0.025      -0.022\n",
      "==============================================================================\n",
      "Omnibus:                   133078.036   Durbin-Watson:                   1.998\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           724503.183\n",
      "Skew:                           1.609   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.972   Cond. No.                         6.58\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "train_f = train_normal.drop('month', axis = 1)\n",
    "\n",
    "# convert dates to categorical\n",
    "train_f['date'] = train_f['date'].astype('category')\n",
    "train_f['weekday'] = train_f['weekday'].astype('category')\n",
    "train_f['hour'] = train_f['hour'].astype('category')\n",
    "train_f['minute'] = train_f['minute'].astype('category')\n",
    "\n",
    "targ = train_f.target\n",
    "train_f = train_f.drop('target', axis = 1)\n",
    "train_f['target'] = targ\n",
    "\n",
    "# dummies\n",
    "#train_f = pd.get_dummies(train_f) \n",
    "\n",
    "# split to train and validation\n",
    "validation_x, train_x = train_test_split(train_f, test_size = 0.9, train_size = 0.1)\n",
    "\n",
    "# separate x and y\n",
    "train_y = train_x.target\n",
    "train_x = train_x.drop('target', axis = 1)\n",
    "\n",
    "validation_y = validation_x.target\n",
    "validation_x = validation_x.drop('target', axis = 1)\n",
    "\n",
    "#fit linear regression model\n",
    "model = sm.OLS(train_y, train_x).fit()\n",
    "\n",
    "#view model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90f1789",
   "metadata": {},
   "source": [
    "# Test Preparation\n",
    "\n",
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "621f97dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_normal.target\n",
    "train_x = train_normal.drop('target', axis = 1)\n",
    "\n",
    "train_x = train_x.drop('month', axis = 1)\n",
    "\n",
    "# convert dates to categorical\n",
    "train_x['date'] = train_x['date'].astype('category')\n",
    "train_x['weekday'] = train_x['weekday'].astype('category')\n",
    "train_x['hour'] = train_x['hour'].astype('category')\n",
    "train_x['minute'] = train_x['minute'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20a45f3",
   "metadata": {},
   "source": [
    "## Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4719b3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_a = train.iloc[:,0:7].columns.to_list()\n",
    "feature_b = train.iloc[:,8:-1].columns.to_list()\n",
    "normal_standard = ColumnTransformer([('standardscaler', StandardScaler(), feature_a)], \n",
    "                                    remainder='passthrough')\n",
    "normal_minmax = ColumnTransformer([('minmaxscaler', MinMaxScaler(), feature_b)], \n",
    "                                  remainder='passthrough')\n",
    "\n",
    "test = pd.read_csv(\"./test_data_nolabels.csv\")\n",
    "\n",
    "# transform test data\n",
    "\n",
    "# get dataid\n",
    "test_id = test.dataid\n",
    "\n",
    "# change type from string to datetime object\n",
    "test.localminute = pd.to_datetime(test.localminute)\n",
    "\n",
    "# create new columns\n",
    "test['date'] = test.localminute.dt.day\n",
    "test['weekday'] = test.localminute.dt.weekday\n",
    "test['hour'] = test.localminute.dt.hour\n",
    "test['minute'] = test.localminute.dt.minute\n",
    "\n",
    "# remove localminute and dataid column\n",
    "test = test.drop(['dataid', 'localminute'], axis = 1)\n",
    "\n",
    "col_names = test.columns\n",
    "\n",
    "# normalise test data\n",
    "test = pd.DataFrame(normal_standard.fit_transform(test))\n",
    "# rename columns\n",
    "test.columns = col_names\n",
    "# do the rest\n",
    "test = pd.DataFrame(normal_minmax.fit_transform(test))\n",
    "# rename columns\n",
    "test.columns = feature_b + feature_a\n",
    "\n",
    "# select test columns\n",
    "#test = test[features]\n",
    "\n",
    "# convert dates to categorical\n",
    "test['date'] = test['date'].astype('category')\n",
    "test['weekday'] = test['weekday'].astype('category')\n",
    "test['hour'] = test['hour'].astype('category')\n",
    "test['minute'] = test['minute'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d24e2d1",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1de6acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    98416\n",
      "1     6536\n",
      "Name: target, dtype: int64\n",
      "[[-0.43011004  0.14269358 -1.48071357 -0.08601288  1.83567011 -0.15163288\n",
      "   0.09867033  1.68454476  0.76459465 -1.35974101 -0.97647455]] [-5.83595267]\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(max_iter=1000).fit(train_x, train_y)\n",
    "\n",
    "lr_test = lr_model.predict(test).astype('int')\n",
    "\n",
    "lr_final = pd.DataFrame({\"dataid\" : test_id, \"target\" : lr_test})\n",
    "lr_final.to_csv(\"predict_label.csv\", index = False)\n",
    "print(lr_final.target.value_counts())\n",
    "print(lr_model.coef_, lr_model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b968539d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
